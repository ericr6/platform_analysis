{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ericr6/platform_analysis/blob/main/hw_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Hello World Monitoring\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "# @title import stuffs\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "# Assuming your DataFrame is named 'df'\n",
    "# Convert DATE column to datetime if it's not already\n",
    "# Replace 'specific_workerpool_id' with the actual ID of the worker pool you're interested in\n",
    "\n",
    "def taskperday(df,workerpool_id, wpname):\n",
    "\n",
    "    # Filter the DataFrame further for the specific worker pool\n",
    "    df_taskday = df[df['WORKERPOOL ID'] == workerpool_id]\n",
    "    len(df_taskday)\n",
    "\n",
    "    df_taskday['DATE'] = pd.to_datetime(df_taskday['DATE'])\n",
    "    # Define the date interval\n",
    "    start_date = df_taskday['DATE'].min().strftime(\"%Y-%m-%d\")\n",
    "    end_date = df_taskday['DATE'].max().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Extract month from the DATE column\n",
    "    df_taskday['Day'] = df_taskday['DATE'].dt.to_period('d')\n",
    "\n",
    "    # Group by Month and STATUS, count occurrences\n",
    "    status_counts = df_taskday.groupby(['Day', 'STATUS']).size().unstack(fill_value=0)\n",
    "\n",
    "    # Plot\n",
    "    status_counts.plot(kind='bar', stacked=True, figsize=(20, 8))\n",
    "\n",
    "    plt.title('Tasks per day \\n (Workerpool: {}) \\n {} Start Date: {} | End Date: {}'.format(workerpool_id, wpname, start_date, end_date))\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Status')\n",
    "\n",
    "    #Upscale resolution\n",
    "    plt.figure(dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Assuming df is your DataFrame containing the dApps data\n",
    "# Filter the DataFrame based on the 'WORKERPOOL ID'\n",
    "#workerpool_filter = ('0x0e7bc972c99187c191a17f3cae4a2711a4188c3f','0xdb214a4a444d176e22030be1ed89da1b029320f2')\n",
    "#duration=(1,7,30);\n",
    "\n",
    "\n",
    "def taskplot(df,workerpool_filter, duration, wp_name):\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=duration)\n",
    "    date_filtered_df = df[(df['DATE'] >= start_date) & (df['DATE'] <= end_date)]\n",
    "    filtered_df = date_filtered_df[date_filtered_df['WORKERPOOL ID'] == workerpool_filter]\n",
    "\n",
    "    # Group by app name and date to count the number of uses of each dApp on each date\n",
    "    app_usage = filtered_df.groupby(['APP NAME', pd.Grouper(key='DATE', freq='D')]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Get unique app names for y-axis ticks\n",
    "    dapp_names = app_usage.index\n",
    "\n",
    "    # Calculate figsize based on the number of dApps\n",
    "    fig_height = max(1, len(dapp_names) * 0.5)  # Minimum height of 6 inches\n",
    "    plt.figure(figsize=(25, fig_height))\n",
    "\n",
    "    # Plot usage events for each dApp\n",
    "    for i, app in enumerate(dapp_names):\n",
    "        usage_dates = filtered_df[filtered_df['APP NAME'] == app]['DATE']\n",
    "        plt.plot(usage_dates, [i] * len(usage_dates), marker='o', linestyle='', markersize=5, label=app)\n",
    "\n",
    "    start_date_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "    end_date_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "    plt.title('Usage of dApps Over Time \\n Workerpool: {} \\n {} \\n Last {} day(s)  [{} -> {}]'.format(wp_name,workerpool_filter, str(duration), start_date_str, end_date_str))\n",
    "\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "    plt.ylabel('dApp')\n",
    "    plt.yticks(range(len(dapp_names)), dapp_names)  # Set y-axis ticks to be the unique app names\n",
    "    # Extend y-axis plot\n",
    "    plt.ylim(-0.5, len(dapp_names) - 0.5)\n",
    "\n",
    "  #plt.legend()  # Add legend to show dApp names\n",
    "\n",
    "    plt.grid(axis='y')\n",
    "    plt.show()    \n",
    "\n",
    "\n",
    "# Function to calculate the percentage of successful tasks\n",
    "def calculate_success_percentage(total_tasks, successful_tasks):\n",
    "    if total_tasks == 0:\n",
    "        return 0\n",
    "    return (successful_tasks / total_tasks) * 100\n",
    "\n",
    "# Function to plot a pie chart with percentage and value\n",
    "def plot_pie_chart(ax, successful_tasks, total_tasks, title):\n",
    "    success_percentage = calculate_success_percentage(total_tasks, successful_tasks)\n",
    "    failed_tasks = total_tasks - successful_tasks\n",
    "\n",
    "    ax.pie([successful_tasks, failed_tasks], labels=[f'Successful Tasks ({successful_tasks})', f'Failed Tasks ({failed_tasks})'], autopct='%1.1f%%', startangle=140,colors=['lightgreen', 'lightcoral'])\n",
    "    ax.title(title + f' ({success_percentage:.2f}% success)', fontsize=12, fontweight='bold')\n",
    "    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "    ax.legend(loc='upper right', fontsize=10)\n",
    "\n",
    "# Define the date interval\n",
    "date_begin = df_tasks_30d['DATE'].min().strftime(\"%Y-%m-%d\")\n",
    "date_end = df_tasks_30d['DATE'].max().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Assuming 'df_tasks_30d' is your DataFrame with task data\n",
    "\n",
    "\n",
    "\n",
    "def successrate(dftmp, workerpool_filter, duration, wp_name ):\n",
    "  # Calculate the date range for each time interval\n",
    "  # Replace 'specific_workerpool_id' with the actual ID of the worker pool you're interested in\n",
    "  \n",
    "  end_date = datetime.now()\n",
    "  start_date = end_date - timedelta(days=duration)\n",
    "\n",
    "  # Filter the DataFrame for each time interval\n",
    "  df_datefiltered = dftmp[(dftmp['DATE'] >= start_date) & (dftmp['DATE'] <= end_date)]\n",
    "\n",
    "  # Filter the DataFrame further for the specific worker pool\n",
    "  df_tmp = df_datefiltered[df_datefiltered['WORKERPOOL ID'] == workerpool_filter]\n",
    "\n",
    "\n",
    "  # Calculate the total number of tasks and successful tasks for each time interval\n",
    "  total_tasks = len(df_tmp)\n",
    "  successful_tasks = len(df_tmp[df_tmp['STATUS'] == 'COMPLETED'])\n",
    "  \n",
    "  # Create a figure with subplots\n",
    "#  fig, axs = plt.subplots(1, 4, figsize=(20, 8))\n",
    "  # Plot pie charts for each time interval\n",
    "\n",
    "  start_date_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "  end_date_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "  title=('Success Rate on {} \\n Workerpool: \\n {} \\n Last {} day(s) \\n [{} -> {}]'.format(wp_name,workerpool_prod, str(duration), start_date_str, end_date_str))\n",
    " \n",
    "  plot_pie_chart( plt, successful_tasks, total_tasks, title)\n",
    "  \n",
    "  # Adjust layout and show plot\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "def success_repartition(df_tmp, workerpool, duration, wp_name):\n",
    "\n",
    "    # Filter the DataFrame for the last day\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=duration)\n",
    "    df_datefiltered = df_tmp[(df_tmp['DATE'] >= start_date) & (df_tmp['DATE'] <= end_date)]\n",
    "    # Filter the DataFrame further for the specific worker pool\n",
    "    df_wpfiltered = df_datefiltered[df_datefiltered['WORKERPOOL ID'] == workerpool]\n",
    "\n",
    "    # Create a dictionary to map DApp names to colors and marker types\n",
    "    dapp_info = {}\n",
    "    for i, dapp in enumerate(df_wpfiltered['APP NAME'].unique()):\n",
    "        dapp_info[dapp] = {\n",
    "            'color': plt.cm.tab20(i/len(df_wpfiltered['APP NAME'].unique())),\n",
    "            'marker': 'o'  # Use the same marker type for each DApp\n",
    "        }\n",
    "\n",
    "    # Plot successful and unsuccessful points using the same marker type per DApp\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    for dapp, info in dapp_info.items():\n",
    "        dapp_df = df_wpfiltered[df_wpfiltered['APP NAME'] == dapp]\n",
    "        success_mask = dapp_df['STATUS'] == 'COMPLETED'\n",
    "\n",
    "        # Generate random y-coordinates for successful points in the range [0.1, 1]\n",
    "        random_success_y = np.random.uniform(low=0.1, high=1, size=np.sum(success_mask))\n",
    "        # Generate random y-coordinates for unsuccessful points in the range [-1, -0.1]\n",
    "        random_failure_y = np.random.uniform(low=-1, high=-0.1, size=np.sum(~success_mask))\n",
    "\n",
    "        # Plot successful points\n",
    "        plt.scatter(dapp_df['DATE'][success_mask], random_success_y, color=info['color'], label=f'{dapp}', marker=info['marker'])\n",
    "        # Plot unsuccessful points\n",
    "        plt.scatter(dapp_df['DATE'][~success_mask], random_failure_y, color=info['color'], marker=info['marker'])\n",
    "\n",
    "    start_date_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "    end_date_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "    title=('Tasks Success/fail distribution on \\n {}  \\n Workerpool: \\n {} \\n Last {} day(s) \\n [{} -> {}]'.format(wp_name, workerpool, str(duration), start_date_str, end_date_str))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Task Status')\n",
    "    plt.yticks([-1, 0, 1], ['Failed', '', 'Success'])\n",
    "\n",
    "    # Create a single legend for both success and failure\n",
    "    plt.legend(title='DApp', loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def successrate_app(df_tmp, workerpool, wp_name):\n",
    "    # Filter the DataFrame to include only tasks associated with the specified workerpool\n",
    "    workerpool_df = df_tmp[df_tmp['WORKERPOOL ID'] == workerpool]\n",
    "\n",
    "    # Define the date interval\n",
    "    date_begin = df_tmp['DATE'].min().strftime(\"%Y-%m-%d\")\n",
    "    date_end = df_tmp['DATE'].max().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Calculate the success ratio for each DApp within the specified workerpool\n",
    "    dapp_data = {}\n",
    "    for dapp, group in workerpool_df.groupby('APP NAME'):\n",
    "        total_count = group.shape[0]\n",
    "        success_count = group[group['STATUS'] == 'COMPLETED'].shape[0]\n",
    "        ratio = success_count / total_count if total_count != 0 else 0\n",
    "        dapp_data[dapp] = {'ratio': ratio, 'success_count': success_count, 'total_count': total_count}\n",
    "\n",
    "    # Sort the dapp_data dictionary by the total_count of tasks\n",
    "    sorted_dapp_data = dict(sorted(dapp_data.items(), key=lambda item: item[1]['total_count'], reverse=False))\n",
    "\n",
    "    # Create a bar plot\n",
    "    fig_height = max(1, len(sorted_dapp_data) * 0.3)  # Calculate figsize based on the number of dApps\n",
    "    plt.figure(figsize=(25, fig_height))\n",
    "\n",
    "    plt.barh(list(sorted_dapp_data.keys()), [d['ratio'] for d in sorted_dapp_data.values()], color='lightgreen', label='Success Ratio')\n",
    "    plt.xlabel('Success Ratio')\n",
    "    plt.ylabel('DApp')\n",
    "    plt.title(f'Success Ratio of Tasks for Each DApp \\n ({date_begin} to {date_end}) \\n Workerpool {wp_name} : {workerpool}')\n",
    "    plt.legend()\n",
    "\n",
    "    # Add annotations for success ratio and total task count\n",
    "    for i, (dapp, data) in enumerate(sorted_dapp_data.items()):\n",
    "        plt.text(data['ratio'], i, f'{data[\"ratio\"]:.2f} {data[\"success_count\"]} out of {data[\"total_count\"]} tasks', verticalalignment='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Requester Activity Analysis for a defined app in last days\n",
    "\n",
    "def req_plot(df,workerpool_filter, duration, wp_name, app):\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=duration)\n",
    "    date_filtered_df = df[(df['DATE'] >= start_date) & (df['DATE'] <= end_date)]\n",
    "    filtered_df = date_filtered_df[date_filtered_df['WORKERPOOL ID'] == workerpool_filter]\n",
    "    filteredapp_df = filtered_df[filtered_df['APP NAME'] == app]\n",
    "\n",
    "\n",
    "    # Group by app name and date to count the number of uses of each dApp on each date\n",
    "    # req_usage = filteredapp_df.groupby(['REQUESTER ID', pd.Grouper(key='DATE', freq='D')]).size().unstack(fill_value=0)\n",
    "    # Define colors for different statuses\n",
    "    status_colors = {'COMPLETED': 'green', 'ACTIVE': 'red'}\n",
    "    address_counts = filteredapp_df['REQUESTER ID'].value_counts()\n",
    " \n",
    "\n",
    "    # Create a scatter plot with conditional coloring based on the status\n",
    "    plt.figure(figsize=(20, 14))\n",
    "    annotated_ids = set()  # Initialize a set to keep track of annotated IDs\n",
    "    for status, color in status_colors.items():\n",
    "        status_df = filteredapp_df[filteredapp_df['STATUS'] == status]\n",
    "        plt.scatter(status_df['DATE'], status_df['REQUESTER ID'], marker='o', color=color, label=status)\n",
    "\n",
    "        # Annotate points with the number of points for each address\n",
    "        for idx, row in status_df.iterrows():\n",
    "            if row['REQUESTER ID'] not in annotated_ids:  # Check if ID has not been annotated yet\n",
    "                plt.annotate(str(address_counts[row['REQUESTER ID']]), (row['DATE'], row['REQUESTER ID']), textcoords=\"offset points\", xytext=(-10,0), ha='right')\n",
    "                annotated_ids.add(row['REQUESTER ID'])  # Add ID to annotated set\n",
    "\n",
    "    # Set plot title and labels\n",
    "    start_date_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "    end_date_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "    plt.title('Scatter Plot of Requesters for \\n DApp {} \\n Workerpool: {} ; {}\\n Last {} day(s)    [{} -> {}]'.format(app, wp_name, workerpool_filter, duration, start_date_str, end_date_str))\n",
    "\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Requester')\n",
    "\n",
    "    # Rotate x-axis labels for better readability if needed\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Show plot\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Requester usage of specific app and workerpool in last days\n",
    "\n",
    "def req_count(df,workerpool_filter, duration, wp_name, app):\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=duration)\n",
    "    date_filtered_df = df[(df['DATE'] >= start_date) & (df['DATE'] <= end_date)]\n",
    "    filtered_df = date_filtered_df[date_filtered_df['WORKERPOOL ID'] == workerpool_filter]\n",
    "    filteredapp_df = filtered_df[filtered_df['APP NAME'] == app]\n",
    "\n",
    "\n",
    "    # Group by 'APP NAME' and 'STATUS' and count occurrences\n",
    "    app_counts = filteredapp_df.groupby(['REQUESTER ID', 'STATUS']).size()\n",
    "\n",
    "    # Reset index to make 'APP NAME' and 'STATUS' as columns\n",
    "    app_counts_df = app_counts.reset_index(name='Number of Occurrences')\n",
    "\n",
    "    # Pivot the DataFrame to have 'STATUS' as columns\n",
    "    app_counts_pivot = app_counts_df.pivot(index='REQUESTER ID', columns='STATUS', values='Number of Occurrences')\n",
    "\n",
    "    # Replace NaN values with zero\n",
    "    app_counts_pivot.fillna(0, inplace=True)\n",
    "\n",
    "    # Convert the DataFrame to use integer data type\n",
    "    app_counts_pivot = app_counts_pivot.astype(int)\n",
    "\n",
    "    # Add 'COMPLETED' column as sum of 'COMPLETED' and 'FAILED' columns\n",
    "    app_counts_pivot['COMPLETED'] = app_counts_pivot['COMPLETED']\n",
    "\n",
    "    # Sort the DataFrame based on 'COMPLETED' column\n",
    "    app_counts_pivot_sorted = app_counts_pivot.sort_values(by='COMPLETED', ascending=False)\n",
    "\n",
    "    # Print the DataFrame completely\n",
    "    start_date_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "    end_date_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "    print('Requester Activity for DApp {} on Workerpool: {} ; {}  Last {} day(s)    [{} -> {}]'.format(app, wp_name, workerpool_filter, duration, start_date_str, end_date_str))\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # Display all rows and columns\n",
    "        print(app_counts_pivot_sorted)\n",
    "\n",
    "def req_count_with_detail(df, workerpool_filter, duration, wp_name, app):\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=duration)\n",
    "    \n",
    "    # Filter data by date and workerpool\n",
    "    date_filtered_df = df[(df['DATE'] >= start_date) & (df['DATE'] <= end_date)]\n",
    "    filtered_df = date_filtered_df[date_filtered_df['WORKERPOOL ID'] == workerpool_filter]\n",
    "    filteredapp_df = filtered_df[filtered_df['APP NAME'] == app]\n",
    "    \n",
    "    # First, get APP MULTIADDR analysis\n",
    "    app_multiaddr_analysis = filteredapp_df.groupby('APP MULTIADDR')['REQUESTER ID'].unique()\n",
    "    \n",
    "    # Group by 'APP NAME' and 'STATUS' and count occurrences\n",
    "    app_counts = filteredapp_df.groupby(['REQUESTER ID', 'STATUS']).size()\n",
    "    \n",
    "    # Reset index to make 'APP NAME' and 'STATUS' as columns\n",
    "    app_counts_df = app_counts.reset_index(name='Number of Occurrences')\n",
    "    \n",
    "    # Pivot the DataFrame to have 'STATUS' as columns\n",
    "    app_counts_pivot = app_counts_df.pivot(index='REQUESTER ID', columns='STATUS', values='Number of Occurrences')\n",
    "    \n",
    "    # Replace NaN values with zero\n",
    "    app_counts_pivot.fillna(0, inplace=True)\n",
    "    \n",
    "    # Convert the DataFrame to use integer data type\n",
    "    app_counts_pivot = app_counts_pivot.astype(int)\n",
    "    \n",
    "    # Add 'COMPLETED' column as sum of 'COMPLETED' and 'FAILED' columns\n",
    "    app_counts_pivot['COMPLETED'] = app_counts_pivot['COMPLETED']\n",
    "    \n",
    "    # Add APP MULTIADDR column\n",
    "    requester_app_multiaddr = filteredapp_df.groupby('REQUESTER ID')['APP MULTIADDR'].first()\n",
    "    app_counts_pivot['APP MULTIADDR'] = app_counts_pivot.index.map(requester_app_multiaddr)\n",
    "    \n",
    "    # Sort the DataFrame based on 'COMPLETED' column\n",
    "    app_counts_pivot_sorted = app_counts_pivot.sort_values(by='COMPLETED', ascending=False)\n",
    "    \n",
    "    # Reorder columns to put APP MULTIADDR first\n",
    "    cols = app_counts_pivot_sorted.columns.tolist()\n",
    "    final_cols = ['APP MULTIADDR'] + [col for col in cols if col != 'APP MULTIADDR']\n",
    "    app_counts_pivot_sorted = app_counts_pivot_sorted[final_cols]\n",
    "    \n",
    "    # Print the results\n",
    "    start_date_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "    end_date_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "    print('Requester Activity for DApp {} on Workerpool: {} ; {}  Last {} day(s)    [{} -> {}]'.format(\n",
    "        app, wp_name, workerpool_filter, duration, start_date_str, end_date_str))\n",
    "    \n",
    "    # Print APP MULTIADDR analysis\n",
    "    print(\"\\nAPP MULTIADDR Analysis:\")\n",
    "    print(\"-\" * 50)\n",
    "    for multiaddr, requesters in app_multiaddr_analysis.items():\n",
    "        print(f\"\\nAPP MULTIADDR: {multiaddr}\")\n",
    "        print(\"Associated Requesters:\")\n",
    "        for requester in requesters:\n",
    "            print(f\"  - {requester}\")\n",
    "    print(\"\\n\" + \"-\" * 50 + \"\\n\")\n",
    "    \n",
    "    # Print the main activity table\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(\"Detailed Activity by Requester:\")\n",
    "        print(app_counts_pivot_sorted)\n",
    "\n",
    "    print('Requester Activity for DApp {} on Workerpool: {} ; {}  Last {} day(s)    [{} -> {}]'.format(app, wp_name, workerpool_filter, duration, start_date_str, end_date_str))\n",
    "\n",
    "\n",
    "#print(filename)\n",
    "\n",
    "# @title Common Functions\n",
    "# Function to convert Hexa String to Text\n",
    "def hex_to_string(value):\n",
    "    if not value:\n",
    "        return value\n",
    "\n",
    "    bytes_from_hex = bytes.fromhex(value[2:])\n",
    "    return bytes_from_hex.decode('utf-8')\n",
    "\n",
    "def filter_by_time_interval(data_list, date_begin, date_end):\n",
    "    # Convert date_begin and date_end strings to datetime objects\n",
    "    #date_begin = datetime.strptime(date_begin, '%Y-%m-%d %H:%M:%S')\n",
    "    #date_end = datetime.strptime(date_end, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Filter data_list based on timestamp falling within the specified time interval\n",
    "    filtered_data = [row for row in data_list if date_begin <= datetime.utcfromtimestamp(int(row[5])) <= date_end]\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "\n",
    "def get_api_data_iexec_interval(url_query, query, global_skip, date_begin=None, date_end=None):\n",
    "    total_data = []\n",
    "    are_data = True\n",
    "    detected = False\n",
    "    skip = 0\n",
    "    while are_data and skip < 200000 or not detected:\n",
    "\n",
    "        # Construct the query with skip parameter and optional date filters\n",
    "        query_iter = query.replace(\"skip_param\", str(global_skip + skip))\n",
    "\n",
    "        options = {\n",
    "            'headers': {'Content-Type': 'application/json'},\n",
    "            'data': '{\"query\": \"' + query_iter + '\"}',\n",
    "        }\n",
    "\n",
    "        response = requests.post(url_query, **options)\n",
    "\n",
    "        # Check if the response contains valid JSON data\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        array_data = data.get('data', {}).get('taskInitializes', [])\n",
    "\n",
    "        grouped = [\n",
    "            [\n",
    "                e['task']['id'],\n",
    "                e['task']['deal']['app']['name'],\n",
    "                hex_to_string(e['task']['deal']['app']['multiaddr']),\n",
    "                e['task']['deal']['tag'],\n",
    "                e['task']['status'],\n",
    "                #pd.to_datetime(int(e['task']['timestamp']) * 1000000).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                e['task']['timestamp'],\n",
    "                e['task']['deal']['workerpool']['id'],\n",
    "                e['task']['deal']['requester']['id']\n",
    "            ]\n",
    "            for e in array_data\n",
    "        ]\n",
    "\n",
    "        grouped = filter_by_time_interval(grouped, date_begin, date_end)\n",
    "\n",
    "        total_data.extend(grouped)\n",
    "        skip += 500\n",
    "        _are_data = len(grouped) > 0\n",
    "        if _are_data > 0 and are_data:\n",
    " #           print (\"detected is true\")\n",
    "            detected = True\n",
    "        are_data = len(grouped) > 0\n",
    "        print(\"i= \" + str(global_skip + skip) + \" are_data: \" + str(are_data) + \"_are_data: \" + str(_are_data) + \" grouped size \" +  str(len(grouped)) + \" array_data size: \" + str(len(array_data))  )\n",
    "    return total_data\n",
    "\n",
    "\n",
    "\n",
    "# Actualize data\n",
    "url_query_bellecour = 'https://thegraph.bellecour.iex.ec/subgraphs/name/bellecour/poco-v5'\n",
    "query = '{\\\n",
    "                taskInitializes(first:500, skip: skip_param, orderBy: timestamp, orderDirection: desc){\\\n",
    "                  task{\\\n",
    "                    id,\\\n",
    "                    deal{\\\n",
    "                      requester {\\\n",
    "                        id\\\n",
    "                      }\\\n",
    "                      app{\\\n",
    "                        name\\\n",
    "                        multiaddr\\\n",
    "                      }\\\n",
    "                      dataset{\\\n",
    "                        name\\\n",
    "                      }\\\n",
    "                      workerpool{\\\n",
    "                        id\\\n",
    "                         }\\\n",
    "                      tag\\\n",
    "                    }\\\n",
    "                    status,\\\n",
    "                    timestamp\\\n",
    "                  }\\\n",
    "                }\\\n",
    "              }'\n",
    "# @title check data set structure\n",
    "\n",
    "\n",
    "# @title Get latest data ; Select N Days\n",
    "\n",
    "date_end = datetime.now()\n",
    "date_begin = date_end - timedelta(days=30)\n",
    "\n",
    "print (\"Period to retrieve:\", date_begin, date_end)\n",
    "\n",
    "api_data = get_api_data_iexec_interval(url_query_bellecour, query, 0, date_begin, date_end)\n",
    "df_tasks_30d = pd.DataFrame(api_data, columns=[\"TASK_ID\",\"APP NAME\", \"APP MULTIADDR\", \"TAG\", \"STATUS\", \"DATE\", \"WORKERPOOL ID\", \"REQUESTER ID\"])\n",
    "df_tasks_30d[\"DATE\"] = [datetime.utcfromtimestamp(int(x)) for x in df_tasks_30d[\"DATE\"]]\n",
    "\n",
    "print(\"Period observed\", df_tasks_30d[\"DATE\"].min(), df_tasks_30d[\"DATE\"].max())\n",
    "print(\"dataset length: \" + str(df_tasks_30d.shape[0]))\n",
    "\n",
    "df_tasks_30d.dtypes\n",
    "\n",
    "# @title check dataset header\n",
    "\n",
    "df_tasks_30d\n",
    "\n",
    "\n",
    "req_plot(df_tasks_30d, v8_learn_debug, 40, \"V8_learn_debug\", \"iexec-hello-world-iapp-0.0.1\")\n",
    "\n",
    "req_count_with_detail(df_tasks_30d, v8_learn_debug, 40, \"V8_learn_debug\", \"iexec-hello-world-iapp-0.0.1\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "EaZrS-L77nBl"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
